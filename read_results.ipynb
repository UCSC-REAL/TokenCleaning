{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results DataFrame (Reordered with Average, Percentage Format):\n",
      "\n",
      "                                                   truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "filtered-cured-50k-rho-baseline-global-llama3b-43           47.93   52.33    26.2  56.91      56.46          46.17  77.12     51.9\n",
      "\n",
      "################################################################################\n",
      "LaTeX Form:\n",
      "################################################################################\n",
      "\\begin{table}\n",
      "\\caption{模型评估结果}\n",
      "\\label{tab:results}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & truthfulqa_mc2 & tydiqa & logiqa & mmlu & hellaswag & arc_challenge & boolq & Average \\\\\n",
      "\\midrule\n",
      "filtered-cured-50k-rho-baseline-global-llama3b-43 & 47.93 & 52.33 & 26.20 & 56.91 & 56.46 & 46.17 & 77.12 & 51.90 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "############# base model #########\n",
    "base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# base_model=\"llama8bai/llama8b-7B-v0.3\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "########### train data tag ###############\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_combine_active-split-data-prop-0.6-fixed-base-loss-using-warmup-label_llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-with-prompt\" \n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama8b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama8b\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b-new\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "######### model-tags ##########\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.7_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-10k-warmup-llama3b\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_all\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.8_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-full-baseline\" \n",
    "# dataset_name=\"filtered-cured-50k-random-baseline\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama8b-global\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama8b-global\" \n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.4_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.5_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.9_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama3b-global-ref-8binst\"\n",
    "# dataset_name=\"base\"\n",
    "\n",
    "# dataset_name=\"full-300k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-sample-llama3b\"\n",
    "# model_tags=[f'{dataset_name}_0', f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4'] #\n",
    "# model_tags=[f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4', f'{dataset_name}_5', f'{dataset_name}_6', f'{dataset_name}_7', f'{dataset_name}_8', f'{dataset_name}_9'] #\n",
    "\n",
    "# dataset_name=\"ds2-10k-infl-scores-global-llama3b\"\n",
    "\n",
    "# valid_dataset_name='gsm' ##mmlu bbh gsm truthfulqa\n",
    "# # dataset_name=f'ds2-10k-infl-scores-global-{valid_dataset_name}-llama3b'\n",
    "# dataset_name=f\"ds2-10k-infl-scores-global-{valid_dataset_name}-llama8b\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-kl-divergence\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-kl-divergence-from-ref-model\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-41\" \n",
    "dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-43\"\n",
    "# model_tags=[f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3'] #\n",
    "model_tags=[f'{dataset_name}']\n",
    "# model_tags=[f'{dataset_name}_4']\n",
    "data_prop = 0.6\n",
    "\n",
    "# if \"0.3\" in dataset_name:\n",
    "#     data_prop = 0.3\n",
    "# elif \"0.4\" in dataset_name:\n",
    "#     data_prop = 0.4\n",
    "# elif \"0.5\" in dataset_name:\n",
    "#     data_prop = 0.5\n",
    "# elif \"0.6\" in dataset_name:\n",
    "#     data_prop = 0.6\n",
    "# elif \"0.7\" in dataset_name:\n",
    "#     data_prop = 0.7\n",
    "# elif \"0.8\" in dataset_name:\n",
    "#     data_prop = 0.8\n",
    "# elif \"0.9\" in dataset_name:\n",
    "#     data_prop = 0.9\n",
    "# else:\n",
    "#     data_prop=0.0\n",
    "\n",
    "\n",
    "TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "\n",
    "results_all = {}\n",
    "for model_tag in model_tags:\n",
    "    \n",
    "    data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "    # temp = os.listdir(data_path)[-1]\n",
    "    \n",
    "    if model_tag != 'base':\n",
    "        exp_files = os.listdir(data_path)\n",
    "        # print(exp_files)\n",
    "        for file_name in exp_files:\n",
    "            if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                temp = file_name\n",
    "    else:\n",
    "        temp = os.listdir(data_path)[0]\n",
    "        # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "    data_path = os.path.join(data_path, temp)\n",
    "    json_files = os.listdir(data_path)\n",
    "\n",
    "    results = {}\n",
    "    for file in json_files:\n",
    "        with open(os.path.join(data_path, file), 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            # print(\"#\"* 50 + \"\\n\")\n",
    "            for task in TASK_LISTS:\n",
    "                if task in temp['results'].keys():\n",
    "                    # print(temp['results'][task])\n",
    "                    \n",
    "                    if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                        metric = 'acc,none'\n",
    "                    elif task == 'gsm8k':\n",
    "                        metric = 'exact_match,strict-match'\n",
    "                    elif task == \"triviaqa\":\n",
    "                        metric = \"exact_match,remove_whitespace\"\n",
    "                    elif task == 'bbh':\n",
    "                        metric = 'exact_match,get-answer' \n",
    "                    results[task] = temp['results'][task][metric]\n",
    "    \n",
    "    ####### tydiqa file #########\n",
    "    if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "        with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "    ###########################\n",
    "    \n",
    "    results_all[model_tag] = results\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\" ] #\n",
    "# TASK_LISTS=[\"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']\n",
    "\n",
    "# TASK_LISTS=['truthfulqa_mc2', \"tydiqa\", \"hellaswag\", \"arc_challenge\", \"openbookqa\", \"boolq\"] #\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "# TASK_LISTS=['mmlu', 'bbh',  'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "\n",
    "# TASK_LISTS=[\"sciq\", \"triviaqa\", \"piqa\", 'arc_easy', 'logiqa', 'winogrande']\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\", \"arc_challenge\", \"openbookqa\", 'boolq', 'sciq', \"triviaqa\", \"piqa\", 'arc_easy', 'logiqa',  'winogrande'] ##task\n",
    "\n",
    "# TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"hellaswag\", \"arc_challenge\", \"openbookqa\", 'boolq', 'logiqa'] ##task\n",
    "# TASK_LISTS=['bbh', 'gsm8k']\n",
    "TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "results_df = results_df[TASK_LISTS]\n",
    "results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "results_df = results_df.reindex(model_tags)\n",
    "results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "print(results_df.to_string(line_width=1000))\n",
    "\n",
    "latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "\n",
    "# 打印 LaTeX 表格到控制台\n",
    "print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the overall average result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "############# base model #########\n",
    "base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "########### train data tag ###############\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_combine_active-split-data-prop-0.6-fixed-base-loss-using-warmup-label_llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-with-prompt\" \n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-with-prompt\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama8b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-mistral\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-with-prompt-llama3b-new\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "######### model-tags ##########\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.7_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.3_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-10k-warmup-llama3b\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_all\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.8_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-full-baseline\" \n",
    "# dataset_name=\"filtered-cured-50k-random-baseline\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama8b-global\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-mistral-global\" \n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.4_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.5_llama3b-non-filtered-fixed-base-model\"\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.9_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama3b-global-ref-8binst\"\n",
    "# dataset_name=\"base\"\n",
    "\n",
    "# dataset_name=\"full-300k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model\"\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-sample-llama3b\"\n",
    "# model_tags=[f'{dataset_name}_0', f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4'] #\n",
    "# model_tags=[f'{dataset_name}_1', f'{dataset_name}_2', f'{dataset_name}_3', f'{dataset_name}_4', f'{dataset_name}_5', f'{dataset_name}_6', f'{dataset_name}_7', f'{dataset_name}_8', f'{dataset_name}_9'] #\n",
    "\n",
    "# dataset_name=\"ds2-10k-infl-scores-global-llama3b\"\n",
    "\n",
    "# valid_dataset_name='gsm' ##mmlu bbh gsm truthfulqa\n",
    "# # dataset_name=f'ds2-10k-infl-scores-global-{valid_dataset_name}-llama3b'\n",
    "# dataset_name=f\"ds2-10k-infl-scores-global-{valid_dataset_name}-llama8b\"\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-kl-divergence\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-kl-divergence-from-ref-model\"\n",
    "Train_DATASET_LIST=[\n",
    "        [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"]\n",
    "        [\"filtered-cured-50k-full-baseline-41,\" \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"]\n",
    "        [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"]\n",
    "    [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample-llama3b\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"]\n",
    "    [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global-llama3b\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\" ] \n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "]\n",
    "\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        model_tags=[f'{dataset_name}']\n",
    "        data_prop = 0.6\n",
    "\n",
    "\n",
    "        TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "        \n",
    "        results_all = {}\n",
    "        for model_tag in model_tags:\n",
    "            \n",
    "            data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "            # temp = os.listdir(data_path)[-1]\n",
    "            \n",
    "            if model_tag != 'base':\n",
    "                exp_files = os.listdir(data_path)\n",
    "                # print(exp_files)\n",
    "                for file_name in exp_files:\n",
    "                    if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                        temp = file_name\n",
    "            else:\n",
    "                temp = os.listdir(data_path)[0]\n",
    "                # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "            data_path = os.path.join(data_path, temp)\n",
    "            json_files = os.listdir(data_path)\n",
    "\n",
    "            results = {}\n",
    "            for file in json_files:\n",
    "                with open(os.path.join(data_path, file), 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    # print(\"#\"* 50 + \"\\n\")\n",
    "                    for task in TASK_LISTS:\n",
    "                        if task in temp['results'].keys():\n",
    "                            # print(temp['results'][task])\n",
    "                            \n",
    "                            if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                                metric = 'acc,none'\n",
    "                            elif task == 'gsm8k':\n",
    "                                metric = 'exact_match,strict-match'\n",
    "                            elif task == \"triviaqa\":\n",
    "                                metric = \"exact_match,remove_whitespace\"\n",
    "                            elif task == 'bbh':\n",
    "                                metric = 'exact_match,get-answer' \n",
    "                            results[task] = temp['results'][task][metric]\n",
    "            \n",
    "            ####### tydiqa file #########\n",
    "            if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "                with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "            ###########################\n",
    "            \n",
    "            results_all[model_tag] = results\n",
    "\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "        TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "        results_df = results_df[TASK_LISTS]\n",
    "        results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "        results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "        print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "        results_df = results_df.reindex(model_tags)\n",
    "        results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "        print(results_df.to_string(line_width=1000))\n",
    "\n",
    "        latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "\n",
    "        # 打印 LaTeX 表格到控制台\n",
    "        print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "        print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the results using csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 基础模型设置\n",
    "\n",
    "\n",
    "### llama3b\n",
    "# base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "## mistral\n",
    "base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "Train_DATASET_LIST=[\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-mistral-43\" ],\n",
    "    [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "    [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "    [\"filtered-cured-10k-warmup-mistral-41\", \"filtered-cured-10k-warmup-mistral\", \"filtered-cured-10k-warmup-mistral-43\"],\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-global-41\", \"filtered-cured-50k-rho-baseline-mistral-global\" ,\"filtered-cured-50k-rho-baseline-mistral-global-43\"],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-43_4\"],\n",
    "    ]\n",
    "\n",
    "\n",
    "#### llama8b\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# Train_DATASET_LIST=(\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\",\"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" , \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\", \"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ) \n",
    "\n",
    "# 定义一个大字典来存储所有数据集的结果\n",
    "all_datasets_results = {}\n",
    "\n",
    "\n",
    "# 遍历所有数据集组合\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "    dataset_group_results = {}  # 存储当前数据集组的结果\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        # print(f\"**** current dataset_name: {dataset_name} ***\")\n",
    "        model_tags = [f'{dataset_name}']\n",
    "        data_prop = 0.6\n",
    "        TASK_LISTS = ['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']\n",
    "        \n",
    "        results_all = {}\n",
    "        for model_tag in model_tags:\n",
    "            data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "            # temp = os.listdir(data_path)[-1]\n",
    "            \n",
    "            if model_tag != 'base':\n",
    "                exp_files = os.listdir(data_path)\n",
    "                # print(exp_files)\n",
    "                for file_name in exp_files:\n",
    "                    if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                        temp = file_name\n",
    "                # print(temp)\n",
    "            else:\n",
    "                temp = os.listdir(data_path)[0]\n",
    "                # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "            data_path = os.path.join(data_path, temp)\n",
    "            json_files = os.listdir(data_path)\n",
    "\n",
    "            results = {}\n",
    "            for file in json_files:\n",
    "                with open(os.path.join(data_path, file), 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    # print(\"#\"* 50 + \"\\n\")\n",
    "                    for task in TASK_LISTS:\n",
    "                        if task in temp['results'].keys():\n",
    "                            # print(temp['results'][task])\n",
    "                            \n",
    "                            if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                                metric = 'acc,none'\n",
    "                            elif task == 'gsm8k':\n",
    "                                metric = 'exact_match,strict-match'\n",
    "                            elif task == \"triviaqa\":\n",
    "                                metric = \"exact_match,remove_whitespace\"\n",
    "                            elif task == 'bbh':\n",
    "                                metric = 'exact_match,get-answer' \n",
    "                            results[task] = temp['results'][task][metric]\n",
    "            \n",
    "            ####### tydiqa file #########\n",
    "            if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "                with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "            ###########################\n",
    "            \n",
    "            results_all[model_tag] = results\n",
    "            \n",
    "        results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "        TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "        results_df = results_df[TASK_LISTS]\n",
    "        results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "        results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "        # print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "        results_df = results_df.reindex(model_tags)\n",
    "        results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "        # print(results_df.to_string(line_width=1000))\n",
    "        results_df.to_csv(f'csv_results/{os.path.basename(base_model)}/{dataset_name}_results.csv')\n",
    "        dataset_group_results[dataset_name] = results_all\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the average results for each base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       truthfulqa_mc2         tydiqa        logiqa          mmlu     hellaswag arc_challenge          boolq       Average\n",
      "ds2                       43.5 ± 0.64  43.73 ± 10.49  26.98 ± 1.53  62.56 ± 0.04  61.33 ± 0.23  51.33 ± 0.75   85.05 ± 1.34   53.5 ± 1.06\n",
      "full_token               43.63 ± 0.09   42.35 ± 11.5  25.94 ± 0.63  62.59 ± 0.16  61.11 ± 0.03  50.93 ± 0.35   83.71 ± 0.14   52.87 ± 1.5\n",
      "random                   43.91 ± 0.11   54.09 ± 1.39   26.1 ± 1.12  62.65 ± 0.17   61.1 ± 0.09   50.5 ± 0.48    83.4 ± 0.32  54.53 ± 0.06\n",
      "rho                       44.04 ± 0.1   44.04 ± 9.13  28.01 ± 2.24  62.34 ± 0.19  61.36 ± 0.03  51.48 ± 0.36   82.93 ± 0.31  53.43 ± 0.93\n",
      "fixed_model_cleaning     45.32 ± 0.79  46.94 ± 10.48  26.15 ± 0.47  61.27 ± 0.62  61.55 ± 0.08  51.74 ± 0.87  68.44 ± 11.78  51.63 ± 3.09\n",
      "self_evolving_cleaning   45.42 ± 0.16   38.16 ± 1.02  27.39 ± 0.09  62.31 ± 0.11  61.46 ± 0.06   50.68 ± 0.3   81.49 ± 0.19  52.43 ± 0.25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 基础模型设置\n",
    "# base_model = \"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "\n",
    "base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "Train_DATASET_LIST=[\n",
    "    [\"filtered-cured-10k-warmup-mistral-41\", \"filtered-cured-10k-warmup-mistral\", \"filtered-cured-10k-warmup-mistral-43\"],\n",
    "    [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "    [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-mistral-43\" ],\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-global-41\", \"filtered-cured-50k-rho-baseline-mistral-global\" ,\"filtered-cured-50k-rho-baseline-mistral-global-43\"],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-43_4\"],\n",
    "    ]\n",
    "\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# Train_DATASET_LIST=[\n",
    "#     [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\" ,\"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ]\n",
    "\n",
    "\n",
    "# 定义一个大字典来存储所有数据集的结果\n",
    "all_datasets_results = {}\n",
    "\n",
    "\n",
    "root_path = \"csv_results\"\n",
    "combined_df_all =None\n",
    "overall_average_results = []\n",
    "\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "    average_results = []\n",
    "    data_frames = []\n",
    "    # 读取每个数据集的 CSV 文件\n",
    "    for dataset_name in dataset_names:\n",
    "        data = pd.read_csv(os.path.join(root_path, os.path.basename(base_model), f'{dataset_name}_results.csv'))\n",
    "        data_frames.append(data)\n",
    "\n",
    "\n",
    "    concatenated_data = pd.concat(data_frames, axis=0)\n",
    "    data_for_analysis = concatenated_data.iloc[:, 1:]\n",
    "\n",
    "    # 计算平均值和方差并四舍五入到两位小数\n",
    "    mean_values = data_for_analysis.mean().round(2)\n",
    "    std_dev_values = data_for_analysis.std().round(2)\n",
    "\n",
    "    combined_df = pd.DataFrame({col: f\"{mean} ± {std_dev}\" for col, mean, std_dev in zip(mean_values.index, mean_values, std_dev_values)}, index=[f'{dataset_names[1]}'])\n",
    "    # print(combined_df.to_string(line_width=1000))\n",
    "    overall_average_results.append(combined_df)\n",
    "\n",
    "\n",
    "combined_df_all = pd.concat(overall_average_results, axis=0)\n",
    "combined_df_all.index = ['ds2', 'full_token', 'random', 'rho', 'fixed_model_cleaning','self_evolving_cleaning']\n",
    "print(combined_df_all.to_string(line_width=1000))\n",
    "\n",
    "combined_df_all.to_csv(f'csv_results/{os.path.basename(base_model)}/final_results.csv')\n",
    "\n",
    "\n",
    "# # 打印 LaTeX 表格到控制台\n",
    "# latex_table = combined_df_all.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "# print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "# print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                       truthfulqa_mc2         tydiqa        logiqa          mmlu     hellaswag arc_challenge          boolq       Average\n",
    "ds2                       43.5 ± 0.64  43.73 ± 10.49  26.98 ± 1.53  62.56 ± 0.04  61.33 ± 0.23  51.33 ± 0.75   85.05 ± 1.34   53.5 ± 1.06\n",
    "full_token               43.63 ± 0.09   42.35 ± 11.5  25.94 ± 0.63  62.59 ± 0.16  61.11 ± 0.03  50.93 ± 0.35   83.71 ± 0.14   52.87 ± 1.5\n",
    "random                   43.91 ± 0.11   54.09 ± 1.39   26.1 ± 1.12  62.65 ± 0.17   61.1 ± 0.09   50.5 ± 0.48    83.4 ± 0.32  54.53 ± 0.06\n",
    "rho                       44.04 ± 0.1   44.04 ± 9.13  28.01 ± 2.24  62.34 ± 0.19  61.36 ± 0.03  51.48 ± 0.36   82.93 ± 0.31  53.43 ± 0.93\n",
    "fixed_model_cleaning     45.32 ± 0.79   58.12 ± 0.87  26.15 ± 0.47  61.27 ± 0.62  61.55 ± 0.08  51.74 ± 0.87    82.03 ± 0.05   55.17 ± 3.09\n",
    "self_evolving_cleaning   45.42 ± 0.16   56.17 ± 0.97 27.39 ± 0.09  62.31 ± 0.11  61.46 ± 0.06   50.68 ± 0.3   81.49 ± 0.19  54.99 ± 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Comparison |          LLaMA-3.2-3B | LLaMA-3.1-8B | \n",
    "Fixed-model cleaning v.s. Rho |   (1.77, 0.152)    |   (1.56, 0.193)  | \n",
    "Self-Evolving Cleaning v.s. Rho |  (9.18, 0.001)    |  (3.02, 0.039)   | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate independent results for each random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              47.74   54.33   26.98  65.79      60.57          53.32  83.38     56.0\n",
      "full_token                       49.84   51.76   28.06  65.75      60.28          54.01  83.17     56.1\n",
      "random                           50.31   53.26   27.44  65.90      60.31          54.44  83.38     56.4\n",
      "rho                              56.42   60.97   27.13  65.76      61.95          55.21  82.52     58.6\n",
      "fixed_model_cleaning             55.94   62.13   28.22  65.61      62.00          55.12  82.71     58.8\n",
      "self_evolving_cleaning           59.78   63.63   26.51  65.18      62.62          54.52  82.49     59.2\n",
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              49.57   50.66   27.44  65.80      60.37          53.57  83.38     55.8\n",
      "full_token                       47.51   55.62   28.53  65.78      60.42          54.01  82.49     56.3\n",
      "random                           48.68   55.70   27.29  65.81      60.40          54.09  83.11     56.4\n",
      "rho                              54.63   54.54   28.99  65.74      62.14          54.78  81.66     57.5\n",
      "fixed_model_cleaning             56.02   62.38   28.22  65.71      61.92          55.12  82.67     58.9\n",
      "self_evolving_cleaning           59.58   63.58   26.05  65.07      62.67          54.87  82.49     59.2\n",
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              47.06   54.08   27.60  65.84      60.48          53.23  83.38     56.0\n",
      "full_token                       49.88   50.11   27.60  65.78      60.30          54.35  83.11     55.9\n",
      "random                           50.54   53.32   28.37  65.79      60.24          54.69  83.23     56.6\n",
      "rho                              56.24   59.97   28.22  65.76      61.91          54.87  82.30     58.5\n",
      "fixed_model_cleaning             56.15   61.03   27.75  65.55      61.97          54.87  82.83     58.6\n",
      "self_evolving_cleaning           59.90   65.08   27.13  65.27      62.66          54.87  82.64     59.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 基础模型设置\n",
    "\n",
    "\n",
    "\n",
    "# base_model = \"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "Train_DATASET_LIST=[\n",
    "    [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "    [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "    [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "    [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "    [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\" ,\"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "    ]\n",
    "\n",
    "\n",
    "# 定义一个大字典来存储所有数据集的结果\n",
    "all_datasets_results = {}\n",
    "\n",
    "root_path = \"csv_results\"\n",
    "combined_df_all =None\n",
    "overall_average_results = []\n",
    "\n",
    "for random_seed_idx in range(3):\n",
    "    data_frames = []\n",
    "\n",
    "    for dataset_names in Train_DATASET_LIST:\n",
    "        # 读取每个数据集的 CSV 文件\n",
    "        dataset_name = dataset_names[random_seed_idx]\n",
    "\n",
    "        data = pd.read_csv(os.path.join(root_path, os.path.basename(base_model), f'{dataset_name}_results.csv'))\n",
    "        data.set_index(data.columns[0], inplace=True)\n",
    "        data_frames.append(data)\n",
    "\n",
    "    concatenated_data = pd.concat(data_frames,axis=0)\n",
    "    # combined_df = pd.DataFrame({col: f\"{mean} ± {std_dev}\" for col, mean, std_dev in zip(mean_values.index, mean_values, std_dev_values)}, index=[f'{dataset_names[1]}'])\n",
    "    new_row_names = ['ds2', 'full_token', 'random', 'rho', 'fixed_model_cleaning','self_evolving_cleaning']\n",
    "    concatenated_data.index = new_row_names\n",
    "    \n",
    "    print(concatenated_data.to_string(line_width=1000))\n",
    "    \n",
    "    concatenated_data.to_csv(f'csv_results/{os.path.basename(base_model)}/independent_results_4{1+random_seed_idx}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                      Unnamed: 0  truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "0                                                           filtered-cured-10k-warmup-llama3b-41           40.96   43.71   24.19  56.92      55.75          44.27  77.33     49.0\n",
      "1                                                            filtered-cured-50k-full-baseline-41           44.22   42.52   24.81  57.07      55.56          45.13  74.00     49.0\n",
      "2                                                          filtered-cured-50k-random-baseline-41           43.89   40.30   24.50  57.22      55.54          45.22  74.21     48.7\n",
      "3                                              filtered-cured-50k-rho-baseline-sample-llama3b-41           47.51   51.85   26.20  57.15      56.49          46.43  76.87     51.8\n",
      "4                                              filtered-cured-50k-rho-baseline-global-llama3b-41           47.85   51.44   26.05  57.10      56.50          46.34  77.12     51.8\n",
      "5  filtered-cured-50k-iter-split-global-data-prop-0.6-llama3b-non-filtered-fixed-base-model-41-4           52.92   54.40   28.84  56.35      55.72          46.94  77.21     53.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"csv_results/Llama-3.2-3B/independent_results_41.csv\")\n",
    "print(data.to_string(line_width=1000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
