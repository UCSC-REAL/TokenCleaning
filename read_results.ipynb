{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results DataFrame (Reordered with Average, Percentage Format):\n",
      "\n",
      "                                                         truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "filtered-cured-50k-rho-baseline-llama3b-global-high-ppl           44.28   38.98   23.26  57.01      55.28          44.79  73.63     48.2\n",
      "\n",
      "################################################################################\n",
      "LaTeX Form:\n",
      "################################################################################\n",
      "\\begin{table}\n",
      "\\caption{模型评估结果}\n",
      "\\label{tab:results}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      " & truthfulqa_mc2 & tydiqa & logiqa & mmlu & hellaswag & arc_challenge & boolq & Average \\\\\n",
      "\\midrule\n",
      "filtered-cured-50k-rho-baseline-llama3b-global-high-ppl & 44.28 & 38.98 & 23.26 & 57.01 & 55.28 & 44.79 & 73.63 & 48.20 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "############# base model #########\n",
    "base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# base_model=\"llama8bai/llama8b-7B-v0.3\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "########### train data tag ###############\n",
    "\n",
    "\n",
    "\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-41\" \n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-global-llama3b-43\"\n",
    "# dataset_name=\"filtered-cured-50k-rho-baseline-llama3b-global-low-ppl-0.86\"\n",
    "dataset_name=\"filtered-cured-50k-rho-baseline-llama3b-global-high-ppl\"\n",
    "model_tags=[f'{dataset_name}']\n",
    "data_prop = 0.6\n",
    "\n",
    "TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "\n",
    "results_all = {}\n",
    "for model_tag in model_tags:\n",
    "    \n",
    "    data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "    # temp = os.listdir(data_path)[-1]\n",
    "    \n",
    "    if model_tag != 'base':\n",
    "        exp_files = os.listdir(data_path)\n",
    "        # print(exp_files)\n",
    "        for file_name in exp_files:\n",
    "            if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                temp = file_name\n",
    "    else:\n",
    "        temp = os.listdir(data_path)[0]\n",
    "        # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "    data_path = os.path.join(data_path, temp)\n",
    "    json_files = os.listdir(data_path)\n",
    "\n",
    "    results = {}\n",
    "    for file in json_files:\n",
    "        with open(os.path.join(data_path, file), 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            # print(\"#\"* 50 + \"\\n\")\n",
    "            for task in TASK_LISTS:\n",
    "                if task in temp['results'].keys():\n",
    "                    # print(temp['results'][task])\n",
    "                    \n",
    "                    if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                        metric = 'acc,none'\n",
    "                    elif task == 'gsm8k':\n",
    "                        metric = 'exact_match,strict-match'\n",
    "                    elif task == \"triviaqa\":\n",
    "                        metric = \"exact_match,remove_whitespace\"\n",
    "                    elif task == 'bbh':\n",
    "                        metric = 'exact_match,get-answer' \n",
    "                    results[task] = temp['results'][task][metric]\n",
    "    \n",
    "    ####### tydiqa file #########\n",
    "    if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "        with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "            temp = json.load(f)\n",
    "            results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "    ###########################\n",
    "    \n",
    "    results_all[model_tag] = results\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "\n",
    "TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "results_df = results_df[TASK_LISTS]\n",
    "results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "results_df = results_df.reindex(model_tags)\n",
    "results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "print(results_df.to_string(line_width=1000))\n",
    "\n",
    "latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "\n",
    "# 打印 LaTeX 表格到控制台\n",
    "print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the overall average result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "############# base model #########\n",
    "base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "# base_model=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "########### train data tag ###############\n",
    "\n",
    "Train_DATASET_LIST=[\n",
    "        [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"]\n",
    "        [\"filtered-cured-50k-full-baseline-41,\" \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"]\n",
    "        [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"]\n",
    "    [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample-llama3b\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"]\n",
    "    [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global-llama3b\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\" ] \n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "]\n",
    "\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        model_tags=[f'{dataset_name}']\n",
    "        data_prop = 0.6\n",
    "\n",
    "\n",
    "        TASK_LISTS=['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande'] ##task\n",
    "        \n",
    "        results_all = {}\n",
    "        for model_tag in model_tags:\n",
    "            \n",
    "            data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "            # temp = os.listdir(data_path)[-1]\n",
    "            \n",
    "            if model_tag != 'base':\n",
    "                exp_files = os.listdir(data_path)\n",
    "                # print(exp_files)\n",
    "                for file_name in exp_files:\n",
    "                    if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                        temp = file_name\n",
    "            else:\n",
    "                temp = os.listdir(data_path)[0]\n",
    "                # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "            data_path = os.path.join(data_path, temp)\n",
    "            json_files = os.listdir(data_path)\n",
    "\n",
    "            results = {}\n",
    "            for file in json_files:\n",
    "                with open(os.path.join(data_path, file), 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    # print(\"#\"* 50 + \"\\n\")\n",
    "                    for task in TASK_LISTS:\n",
    "                        if task in temp['results'].keys():\n",
    "                            # print(temp['results'][task])\n",
    "                            \n",
    "                            if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                                metric = 'acc,none'\n",
    "                            elif task == 'gsm8k':\n",
    "                                metric = 'exact_match,strict-match'\n",
    "                            elif task == \"triviaqa\":\n",
    "                                metric = \"exact_match,remove_whitespace\"\n",
    "                            elif task == 'bbh':\n",
    "                                metric = 'exact_match,get-answer' \n",
    "                            results[task] = temp['results'][task][metric]\n",
    "            \n",
    "            ####### tydiqa file #########\n",
    "            if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "                with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "            ###########################\n",
    "            \n",
    "            results_all[model_tag] = results\n",
    "\n",
    "\n",
    "\n",
    "        results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "        TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "        results_df = results_df[TASK_LISTS]\n",
    "        results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "        results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "        print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "        results_df = results_df.reindex(model_tags)\n",
    "        results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "        print(results_df.to_string(line_width=1000))\n",
    "\n",
    "        latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "\n",
    "        # 打印 LaTeX 表格到控制台\n",
    "        print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "        print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the results using csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 基础模型设置\n",
    "\n",
    "\n",
    "### llama3b\n",
    "# base_model=\"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "## mistral\n",
    "# base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "# Train_DATASET_LIST=[\n",
    "#     [\"filtered-cured-50k-rho-baseline-mistral-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-mistral-43\" ],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-10k-warmup-mistral-41\", \"filtered-cured-10k-warmup-mistral\", \"filtered-cured-10k-warmup-mistral-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-mistral-global-41\", \"filtered-cured-50k-rho-baseline-mistral-global\" ,\"filtered-cured-50k-rho-baseline-mistral-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ]\n",
    "\n",
    "\n",
    "base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "Train_DATASET_LIST = [\n",
    "    [\"filtered-cured-10k-warmup-mistral-new-41\",\"filtered-cured-10k-warmup-mistral-new-43\",],\n",
    "    [\"filtered-cured-50k-full-baseline-mistral-41\", \"filtered-cured-50k-full-baseline-mistral-43\",], #\n",
    "    [\"filtered-cured-50k-fixed-model-cleaning-mistral-41\",\"filtered-cured-50k-fixed-model-cleaning-mistral-43\",],\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-new-41\",\"filtered-cured-50k-rho-baseline-mistral-new-43\",],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-new-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-new-43_4\",],\n",
    "]\n",
    "\n",
    "Train_DATASET_LIST = [\n",
    "[\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\"],]\n",
    "\n",
    "\n",
    "#### llama8b\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# Train_DATASET_LIST=(\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\",\"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" , \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\", \"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ) \n",
    "\n",
    "# 定义一个大字典来存储所有数据集的结果\n",
    "all_datasets_results = {}\n",
    "\n",
    "\n",
    "# 遍历所有数据集组合\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "    dataset_group_results = {}  # 存储当前数据集组的结果\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        # print(f\"**** current dataset_name: {dataset_name} ***\")\n",
    "        model_tags = [f'{dataset_name}']\n",
    "        data_prop = 0.6\n",
    "        TASK_LISTS = ['mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', \"arc_challenge\", \"piqa\", \"hellaswag\", \"openbookqa\", \"triviaqa\", 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']\n",
    "        \n",
    "        results_all = {}\n",
    "        for model_tag in model_tags:\n",
    "            data_path = f\"token_selection_results/{data_prop}/{model_tag}/\"\n",
    "            # temp = os.listdir(data_path)[-1]\n",
    "            \n",
    "            if model_tag != 'base':\n",
    "                exp_files = os.listdir(data_path)\n",
    "                # print(exp_files)\n",
    "                for file_name in exp_files:\n",
    "                    if str(data_prop) in file_name and os.path.basename(base_model) in file_name: ## search the file based on data proportion\n",
    "                        temp = file_name\n",
    "                # print(temp)\n",
    "            else:\n",
    "                temp = os.listdir(data_path)[0]\n",
    "                # temp_file_path = [name for name in temp if os.path.isdir(os.path.join(data_path, name))]\n",
    "\n",
    "            data_path = os.path.join(data_path, temp)\n",
    "            json_files = os.listdir(data_path)\n",
    "\n",
    "            results = {}\n",
    "            for file in json_files:\n",
    "                with open(os.path.join(data_path, file), 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    # print(\"#\"* 50 + \"\\n\")\n",
    "                    for task in TASK_LISTS:\n",
    "                        if task in temp['results'].keys():\n",
    "                            # print(temp['results'][task])\n",
    "                            \n",
    "                            if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                                metric = 'acc,none'\n",
    "                            elif task == 'gsm8k':\n",
    "                                metric = 'exact_match,strict-match'\n",
    "                            elif task == \"triviaqa\":\n",
    "                                metric = \"exact_match,remove_whitespace\"\n",
    "                            elif task == 'bbh':\n",
    "                                metric = 'exact_match,get-answer' \n",
    "                            results[task] = temp['results'][task][metric]\n",
    "            \n",
    "            ####### tydiqa file #########\n",
    "            if os.path.exists(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\"):\n",
    "                with open(f\"token_selection_results/{data_prop}/{model_tag}/metrics.json\", 'r') as f:\n",
    "                    temp = json.load(f)\n",
    "                    results['tydiqa'] = round(temp['average']['f1'] / 100, 4)\n",
    "            ###########################\n",
    "            \n",
    "            results_all[model_tag] = results\n",
    "            \n",
    "        results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "        TASK_LISTS=[\"truthfulqa_mc2\", \"tydiqa\", 'logiqa', 'mmlu',  \"hellaswag\", \"arc_challenge\", \"boolq\"]\n",
    "\n",
    "        results_df = results_df[TASK_LISTS]\n",
    "        results_df = results_df.map(lambda x: round(100*x, 2) if pd.notnull(x) else x)\n",
    "        results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "        # print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "        results_df = results_df.reindex(model_tags)\n",
    "        results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "        # print(results_df.to_string(line_width=1000))\n",
    "        results_df.to_csv(f'csv_results/{os.path.basename(base_model)}/{dataset_name}_results.csv')\n",
    "        dataset_group_results[dataset_name] = results_all\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the average results for each base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       truthfulqa_mc2         tydiqa        logiqa          mmlu     hellaswag arc_challenge         boolq       Average\n",
      "ds2                      43.49 ± 0.65    55.12 ± 0.6   27.24 ± 1.7  62.57 ± 0.05  61.36 ± 0.24  51.39 ± 0.81  85.06 ± 1.35   55.2 ± 0.44\n",
      "full_token                43.63 ± 0.1   56.55 ± 0.85  26.15 ± 0.77   62.64 ± 0.2  61.12 ± 0.04  50.88 ± 0.35  83.66 ± 0.16  54.93 ± 0.29\n",
      "random                   43.91 ± 0.11   54.09 ± 1.39   26.1 ± 1.12  62.65 ± 0.17   61.1 ± 0.09   50.5 ± 0.48   83.4 ± 0.32  54.53 ± 0.06\n",
      "rho                      43.89 ± 0.08   56.16 ± 1.43   27.5 ± 1.89  62.46 ± 0.29  61.32 ± 0.04   51.54 ± 0.4  82.64 ± 0.57  55.07 ± 0.51\n",
      "fixed_model_cleaning     44.02 ± 0.45   59.15 ± 0.45  26.15 ± 0.09  60.99 ± 1.19  61.49 ± 0.15  51.94 ± 0.26  83.42 ± 1.71    55.3 ± 0.1\n",
      "self_evolving_cleaning   43.54 ± 1.65  50.86 ± 10.77  27.85 ± 1.29  59.91 ± 2.27  61.36 ± 0.08   52.0 ± 1.17    83.0 ± 1.5   54.07 ± 1.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 基础模型设置\n",
    "# base_model = \"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "\n",
    "# base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "# Train_DATASET_LIST=[\n",
    "#     [\"filtered-cured-10k-warmup-mistral-41\", \"filtered-cured-10k-warmup-mistral\", \"filtered-cured-10k-warmup-mistral-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-mistral-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-mistral-43\" ],\n",
    "#     [\"filtered-cured-50k-rho-baseline-mistral-global-41\", \"filtered-cured-50k-rho-baseline-mistral-global\" ,\"filtered-cured-50k-rho-baseline-mistral-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ]\n",
    "\n",
    "base_model=\"mistralai/Mistral-7B-v0.3\"\n",
    "Train_DATASET_LIST = [\n",
    "    [\"filtered-cured-10k-warmup-mistral-new-41\", \"filtered-cured-10k-warmup-mistral\", \"filtered-cured-10k-warmup-mistral-new-43\",],\n",
    "    [\"filtered-cured-50k-full-baseline-mistral-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-mistral-43\",], \n",
    "    [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "    [\"filtered-cured-50k-rho-baseline-mistral-new-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-mistral-new-43\",],\n",
    "    [\"filtered-cured-50k-fixed-model-cleaning-mistral-41\", \"filtered-cured-50k-rho-baseline-mistral-global\" ,\"filtered-cured-50k-fixed-model-cleaning-mistral-43\",],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-new-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_mistral-non-filtered-fixed-base-model-new-43_4\",],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "# Train_DATASET_LIST=[\n",
    "#     [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "#     [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\" ,\"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "#     ]\n",
    "\n",
    "\n",
    "# 定义一个大字典来存储所有数据集的结果\n",
    "all_datasets_results = {}\n",
    "\n",
    "\n",
    "root_path = \"csv_results\"\n",
    "combined_df_all =None\n",
    "overall_average_results = []\n",
    "\n",
    "for dataset_names in Train_DATASET_LIST:\n",
    "    average_results = []\n",
    "    data_frames = []\n",
    "    # 读取每个数据集的 CSV 文件\n",
    "    for dataset_name in dataset_names:\n",
    "        data = pd.read_csv(os.path.join(root_path, os.path.basename(base_model), f'{dataset_name}_results.csv'))\n",
    "        data_frames.append(data)\n",
    "\n",
    "\n",
    "    concatenated_data = pd.concat(data_frames, axis=0)\n",
    "    data_for_analysis = concatenated_data.iloc[:, 1:]\n",
    "\n",
    "    # 计算平均值和方差并四舍五入到两位小数\n",
    "    mean_values = data_for_analysis.mean().round(2)\n",
    "    std_dev_values = data_for_analysis.std().round(2)\n",
    "\n",
    "    combined_df = pd.DataFrame({col: f\"{mean} ± {std_dev}\" for col, mean, std_dev in zip(mean_values.index, mean_values, std_dev_values)}, index=[f'{dataset_names[1]}'])\n",
    "    # print(combined_df.to_string(line_width=1000))\n",
    "    overall_average_results.append(combined_df)\n",
    "\n",
    "\n",
    "combined_df_all = pd.concat(overall_average_results, axis=0)\n",
    "combined_df_all.index = ['ds2', 'full_token', 'random', 'rho', 'fixed_model_cleaning','self_evolving_cleaning']\n",
    "print(combined_df_all.to_string(line_width=1000))\n",
    "\n",
    "combined_df_all.to_csv(f'csv_results/{os.path.basename(base_model)}/final_results.csv')\n",
    "\n",
    "\n",
    "# latex_table = combined_df_all.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "# print(\"\\n\" +\"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80 )\n",
    "# print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate independent results for each random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              47.74   54.33   26.98  65.79      60.57          53.32  83.38     56.0\n",
      "full_token                       49.84   51.76   28.06  65.75      60.28          54.01  83.17     56.1\n",
      "random                           50.31   53.26   27.44  65.90      60.31          54.44  83.38     56.4\n",
      "rho                              56.42   60.97   27.13  65.76      61.95          55.21  82.52     58.6\n",
      "fixed_model_cleaning             55.94   62.13   28.22  65.61      62.00          55.12  82.71     58.8\n",
      "self_evolving_cleaning           59.78   63.63   26.51  65.18      62.62          54.52  82.49     59.2\n",
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              49.57   50.66   27.44  65.80      60.37          53.57  83.38     55.8\n",
      "full_token                       47.51   55.62   28.53  65.78      60.42          54.01  82.49     56.3\n",
      "random                           48.68   55.70   27.29  65.81      60.40          54.09  83.11     56.4\n",
      "rho                              54.63   54.54   28.99  65.74      62.14          54.78  81.66     57.5\n",
      "fixed_model_cleaning             56.02   62.38   28.22  65.71      61.92          55.12  82.67     58.9\n",
      "self_evolving_cleaning           59.58   63.58   26.05  65.07      62.67          54.87  82.49     59.2\n",
      "                        truthfulqa_mc2  tydiqa  logiqa   mmlu  hellaswag  arc_challenge  boolq  Average\n",
      "ds2                              47.06   54.08   27.60  65.84      60.48          53.23  83.38     56.0\n",
      "full_token                       49.88   50.11   27.60  65.78      60.30          54.35  83.11     55.9\n",
      "random                           50.54   53.32   28.37  65.79      60.24          54.69  83.23     56.6\n",
      "rho                              56.24   59.97   28.22  65.76      61.91          54.87  82.30     58.5\n",
      "fixed_model_cleaning             56.15   61.03   27.75  65.55      61.97          54.87  82.83     58.6\n",
      "self_evolving_cleaning           59.90   65.08   27.13  65.27      62.66          54.87  82.64     59.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# base_model = \"meta-llama/Llama-3.2-3B\"\n",
    "# Train_DATASET_LIST = [\n",
    "#     [\"filtered-cured-10k-warmup-llama3b-41\", \"filtered-cured-10k-warmup-llama3b\", \"filtered-cured-10k-warmup-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-random-baseline\", \"filtered-cured-50k-random-baseline-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-sample-llama3b-41\", \"filtered-cured-50k-rho-baseline-sample\", \"filtered-cured-50k-rho-baseline-sample-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-rho-baseline-global-llama3b-41\", \"filtered-cured-50k-rho-baseline-global\", \"filtered-cured-50k-rho-baseline-global-llama3b-43\"],\n",
    "#     [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-41_4\",\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama3b-non-filtered-fixed-base-model-43_4\"]\n",
    "# ]\n",
    "\n",
    "base_model=\"meta-llama/Llama-3.1-8B\"\n",
    "Train_DATASET_LIST=[\n",
    "    [\"filtered-cured-10k-warmup-llama8b-41\", \"filtered-cured-10k-warmup-llama8b\", \"filtered-cured-10k-warmup-llama8b-43\"],\n",
    "    [\"filtered-cured-50k-full-baseline-41\", \"filtered-cured-50k-shuffle-full-baseline\", \"filtered-cured-50k-full-baseline-43\"],\n",
    "    [\"filtered-cured-50k-random-baseline-41\", \"filtered-cured-50k-shuffle-random-baseline\" ,\"filtered-cured-50k-random-baseline-43\"],\n",
    "    [\"filtered-cured-50k-rho-baseline-llama8b-41\", \"filtered-cured-50k-rho-baseline\", \"filtered-cured-50k-rho-baseline-llama8b-43\" ],\n",
    "    [\"filtered-cured-50k-rho-baseline-llama8b-global-41\", \"filtered-cured-50k-rho-baseline-llama8b-global\" ,\"filtered-cured-50k-rho-baseline-llama8b-global-43\"],\n",
    "    [\"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-41_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model_4\", \"filtered-cured-50k-iter-split-global_data_prop_0.6_llama8b-non-filtered-fixed-base-model-43_4\"],\n",
    "    ]\n",
    "\n",
    "\n",
    "all_datasets_results = {}\n",
    "\n",
    "root_path = \"csv_results\"\n",
    "combined_df_all =None\n",
    "overall_average_results = []\n",
    "\n",
    "for random_seed_idx in range(3):\n",
    "    data_frames = []\n",
    "\n",
    "    for dataset_names in Train_DATASET_LIST:\n",
    "        dataset_name = dataset_names[random_seed_idx]\n",
    "\n",
    "        data = pd.read_csv(os.path.join(root_path, os.path.basename(base_model), f'{dataset_name}_results.csv'))\n",
    "        data.set_index(data.columns[0], inplace=True)\n",
    "        data_frames.append(data)\n",
    "\n",
    "    concatenated_data = pd.concat(data_frames,axis=0)\n",
    "    new_row_names = ['ds2', 'full_token', 'random', 'rho', 'fixed_model_cleaning','self_evolving_cleaning']\n",
    "    concatenated_data.index = new_row_names\n",
    "    \n",
    "    print(concatenated_data.to_string(line_width=1000))\n",
    "    \n",
    "    concatenated_data.to_csv(f'csv_results/{os.path.basename(base_model)}/independent_results_4{1+random_seed_idx}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
